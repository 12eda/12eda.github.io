[{"id":"dd8e371b161018fe37f17369405b9122","title":"深度学习笔记","content":"深度学习\n梯度下降算法：用来优化参数，让模型的预测更准确\n\n1.1  计算梯度\n1.2  更新参数（需要设置好学习率，就是步长）\n1.3  不断重复，直到梯度为零\n新的参数 &#x3D; 旧的参数 - 学习率 × (损失函数在旧参数点的梯度)\n\n最终目标是要使损失函数最小\n训练过程：\n\n3.1 前向传播\n3.2 计算损失（交叉熵损失）\n3.3 反向传播\n3.4 参数更新\n3.5 循环迭代\n\n激活函数：引入非线性（不同任务类型要用不同的激活函数）\nCNN\n\n输入-卷积-激活函数（简单特征到复杂特征的非线性映射）-池化（简化特征）-展平-全连接-输出\n","slug":"深度学习笔记","date":"2025-10-16T16:00:00.000Z","categories_index":"技术","tags_index":"深度学习","author_index":"Qu shubiao"}]