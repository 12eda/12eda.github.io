{"title":"Kaggle房价预测","uid":"99cc996dc0617c9203fb12b8cb30ba1d","slug":"Kaggle房价预测","date":"2025-10-13T16:00:00.000Z","updated":"2025-10-20T14:02:05.729Z","comments":true,"path":"api/articles/Kaggle房价预测.json","keywords":null,"cover":[],"content":"<h1 id=\"Kaggle房价预测\"><a href=\"#Kaggle房价预测\" class=\"headerlink\" title=\"Kaggle房价预测\"></a>Kaggle房价预测</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 若无法获得测试数据，则可根据训练数据计算均值和标准差</span></span><br><span class=\"line\">numeric_features = all_features.dtypes[all_features.dtypes != <span class=\"string\">&#x27;object&#x27;</span>].index</span><br><span class=\"line\"><span class=\"comment\"># 对每个数字特征进行标准化，把数据变成以0为中心，标准差为1的分布</span></span><br><span class=\"line\"><span class=\"comment\"># 数据围绕着0分布，可以将不同尺度的特征放在一起比较，防止差异性带来的权重不平衡问题</span></span><br><span class=\"line\">all_features[numeric_features] = all_features[numeric_features].apply(</span><br><span class=\"line\">    <span class=\"keyword\">lambda</span> x: (x - x.mean()) / (x.std()))</span><br><span class=\"line\"><span class=\"comment\"># 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0</span></span><br><span class=\"line\">all_features[numeric_features] = all_features[numeric_features].fillna(<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/12eda/Pictures@main/image-20251020152754953.png\" alt=\"image-20251020152754953\"></p>\n<p>查看每个特征的数据类型，为后续数据预处理做准备</p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/12eda/Pictures@main/image-20251014171017170.png\" alt=\"image-20251014171017170\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># &quot;Dummy_na=True&quot;将&quot;na&quot;（缺失值）视为有效的特征值，并为其创建指示符特征</span></span><br><span class=\"line\">all_features = pd.get_dummies(all_features, dummy_na=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\">#将类别特征转换为数值形式（独热编码）</span></span><br><span class=\"line\"><span class=\"comment\">#独热编码可以消除数学大小关系，遇到任何新的类别值，就给所有数据创建对应的列</span></span><br><span class=\"line\"><span class=\"comment\">#但会导致特征爆炸性增长</span></span><br><span class=\"line\">all_features = pd.get_dummies(all_features, dummy_na=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/12eda/Pictures@main/image-20251020153146251.png\" alt=\"image-20251020153146251\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#就是一个线性模型，每个参数的权重不一样</span></span><br><span class=\"line\">loss = nn.MSELoss()</span><br><span class=\"line\">in_features = train_features.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_net</span>():</span><br><span class=\"line\">    net = nn.Sequential(nn.Linear(in_features,<span class=\"number\">1</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> net</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">log_rmse</span>(<span class=\"params\">net, features, labels</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 为了在取对数时进一步稳定该值，将小于1的值设置为1</span></span><br><span class=\"line\">    clipped_preds = torch.clamp(net(features), <span class=\"number\">1</span>, <span class=\"built_in\">float</span>(<span class=\"string\">&#x27;inf&#x27;</span>))</span><br><span class=\"line\">    rmse = torch.sqrt(loss(torch.log(clipped_preds),</span><br><span class=\"line\">                           torch.log(labels)))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> rmse.item()</span><br><span class=\"line\"><span class=\"comment\"># 不看绝对数量，看相对比例</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_features, train_labels, test_features, test_labels,</span></span><br><span class=\"line\"><span class=\"params\">          num_epochs, learning_rate, weight_decay, batch_size</span>):</span><br><span class=\"line\">    train_ls, test_ls = [], []</span><br><span class=\"line\">    train_iter = d2l.load_array((train_features, train_labels), batch_size)</span><br><span class=\"line\">    <span class=\"comment\"># 这里使用的是Adam优化算法,还可以防止过拟合</span></span><br><span class=\"line\">    optimizer = torch.optim.Adam(net.parameters(),</span><br><span class=\"line\">                                 lr = learning_rate,</span><br><span class=\"line\">                                 weight_decay = weight_decay)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_epochs):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">            <span class=\"comment\">#训练的老套路</span></span><br><span class=\"line\">            optimizer.zero_grad()</span><br><span class=\"line\">            l = loss(net(X), y)</span><br><span class=\"line\">            l.backward()</span><br><span class=\"line\">            optimizer.step()</span><br><span class=\"line\">        train_ls.append(log_rmse(net, train_features, train_labels))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> test_labels <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            test_ls.append(log_rmse(net, test_features, test_labels))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_ls, test_ls</span><br><span class=\"line\"><span class=\"comment\">#返回训练结果</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_k_fold_data</span>(<span class=\"params\">k, i, X, y</span>):</span><br><span class=\"line\">    <span class=\"keyword\">assert</span> k &gt; <span class=\"number\">1</span></span><br><span class=\"line\">    fold_size = X.shape[<span class=\"number\">0</span>] // k</span><br><span class=\"line\">    X_train, y_train = <span class=\"literal\">None</span>, <span class=\"literal\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(k):</span><br><span class=\"line\">        idx = <span class=\"built_in\">slice</span>(j * fold_size, (j + <span class=\"number\">1</span>) * fold_size)</span><br><span class=\"line\">        X_part, y_part = X[idx, :], y[idx]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> j == i:</span><br><span class=\"line\">            X_valid, y_valid = X_part, y_part</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> X_train <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            X_train, y_train = X_part, y_part</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            X_train = torch.cat([X_train, X_part], <span class=\"number\">0</span>)</span><br><span class=\"line\">            y_train = torch.cat([y_train, y_part], <span class=\"number\">0</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> X_train, y_train, X_valid, y_valid</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">k_fold</span>(<span class=\"params\">k, X_train, y_train, num_epochs, learning_rate, weight_decay,</span></span><br><span class=\"line\"><span class=\"params\">           batch_size</span>):</span><br><span class=\"line\">    train_l_sum, valid_l_sum = <span class=\"number\">0</span>, <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(k):</span><br><span class=\"line\">        data = get_k_fold_data(k, i, X_train, y_train)</span><br><span class=\"line\">        net = get_net()</span><br><span class=\"line\">        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,</span><br><span class=\"line\">                                   weight_decay, batch_size)</span><br><span class=\"line\">        train_l_sum += train_ls[-<span class=\"number\">1</span>]</span><br><span class=\"line\">        valid_l_sum += valid_ls[-<span class=\"number\">1</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> i == <span class=\"number\">0</span>:</span><br><span class=\"line\">            d2l.plot(<span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(<span class=\"number\">1</span>, num_epochs + <span class=\"number\">1</span>)), [train_ls, valid_ls],</span><br><span class=\"line\">                     xlabel=<span class=\"string\">&#x27;epoch&#x27;</span>, ylabel=<span class=\"string\">&#x27;rmse&#x27;</span>, xlim=[<span class=\"number\">1</span>, num_epochs],</span><br><span class=\"line\">                     legend=[<span class=\"string\">&#x27;train&#x27;</span>, <span class=\"string\">&#x27;valid&#x27;</span>], yscale=<span class=\"string\">&#x27;log&#x27;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;折<span class=\"subst\">&#123;i + <span class=\"number\">1</span>&#125;</span>，训练log rmse<span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_ls[-<span class=\"number\">1</span>]):f&#125;</span>, &#x27;</span></span><br><span class=\"line\">              <span class=\"string\">f&#x27;验证log rmse<span class=\"subst\">&#123;<span class=\"built_in\">float</span>(valid_ls[-<span class=\"number\">1</span>]):f&#125;</span>&#x27;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> train_l_sum / k, valid_l_sum / k</span><br><span class=\"line\"><span class=\"comment\">#K折训练算法：将训练集人为的划分成几份，利用其中一份进行验证，剩余的拿来训练。依次充当验证集，最后取平均值，既充分利用了数据，又得到了最公平的模型评估。</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">k, num_epochs, lr, weight_decay, batch_size = <span class=\"number\">5</span>, <span class=\"number\">100</span>, <span class=\"number\">5</span>, <span class=\"number\">0</span>, <span class=\"number\">64</span></span><br><span class=\"line\">train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,</span><br><span class=\"line\">                          weight_decay, batch_size)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;k&#125;</span>-折验证: 平均训练log rmse: <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(train_l):f&#125;</span>, &#x27;</span></span><br><span class=\"line\">      <span class=\"string\">f&#x27;平均验证log rmse: <span class=\"subst\">&#123;<span class=\"built_in\">float</span>(valid_l):f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/12eda/Pictures@main/image-20251020153301296.png\" alt=\"image-20251020153301296\"></p>\n","text":"Kaggle房价预测12345678# 若无法获得测试数据，则可根据训练数据计算均值和标准差numeric_features = all_features.dt...","permalink":"/post/Kaggle房价预测","photos":[],"count_time":{"symbolsCount":"4k","symbolsTime":"4 mins."},"categories":[{"name":"技术","slug":"技术","count":3,"path":"api/categories/技术.json"}],"tags":[{"name":"深度学习","slug":"深度学习","count":3,"path":"api/tags/深度学习.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Kaggle%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B\"><span class=\"toc-text\">Kaggle房价预测</span></a></li></ol>","author":{"name":"Qushubiao","slug":"blog-author","avatar":"https://s2.loli.net/2025/10/18/RHJMI8AE6TVS21l.jpg","link":"/","description":"做难事必有所得","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"ProstaNet","uid":"a51592e2b5599f8db32fcf648d257b16","slug":"ProstaNet (1)","date":"2025-10-15T16:00:00.000Z","updated":"2025-10-20T14:01:07.295Z","comments":true,"path":"api/articles/ProstaNet (1).json","keywords":null,"cover":null,"text":"ProstaNet一.研究背景 天然的蛋白质有时不够稳定 实验方法测定突变对稳定性的影响成本高、耗时长。 现有计算方法分为基于物理模型和基于机器学习的方法，但存...","permalink":"/post/ProstaNet (1)","photos":[],"count_time":{"symbolsCount":"1.6k","symbolsTime":"1 mins."},"categories":[{"name":"组会","slug":"组会","count":3,"path":"api/categories/组会.json"}],"tags":[{"name":"文献","slug":"文献","count":3,"path":"api/tags/文献.json"}],"author":{"name":"Qushubiao","slug":"blog-author","avatar":"https://s2.loli.net/2025/10/18/RHJMI8AE6TVS21l.jpg","link":"/","description":"做难事必有所得","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"序列数据","uid":"0ef6094797649f91ccbc2e9b364eb919","slug":"序列数据","date":"2025-10-11T16:00:00.000Z","updated":"2025-10-20T14:03:15.583Z","comments":true,"path":"api/articles/序列数据.json","keywords":null,"cover":[],"text":"序列数据12345678T = 1000 # 总共产生1000个点time = d2l.arange(1, T + 1, dtype=d2l.float32)#...","permalink":"/post/序列数据","photos":[],"count_time":{"symbolsCount":"3.5k","symbolsTime":"3 mins."},"categories":[{"name":"技术","slug":"技术","count":3,"path":"api/categories/技术.json"}],"tags":[{"name":"深度学习","slug":"深度学习","count":3,"path":"api/tags/深度学习.json"}],"author":{"name":"Qushubiao","slug":"blog-author","avatar":"https://s2.loli.net/2025/10/18/RHJMI8AE6TVS21l.jpg","link":"/","description":"做难事必有所得","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}