{"title":"序列数据","uid":"0ef6094797649f91ccbc2e9b364eb919","slug":"序列数据","date":"2025-10-11T16:00:00.000Z","updated":"2025-10-20T14:03:15.583Z","comments":true,"path":"api/articles/序列数据.json","keywords":null,"cover":[],"content":"<h1 id=\"序列数据\"><a href=\"#序列数据\" class=\"headerlink\" title=\"序列数据\"></a>序列数据</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">T = <span class=\"number\">1000</span>  <span class=\"comment\"># 总共产生1000个点</span></span><br><span class=\"line\">time = d2l.arange(<span class=\"number\">1</span>, T + <span class=\"number\">1</span>, dtype=d2l.float32)</span><br><span class=\"line\"><span class=\"comment\">#定义时间序列的长度（横轴）为1000个点</span></span><br><span class=\"line\">x = d2l.sin(<span class=\"number\">0.01</span> * time) + d2l.normal(<span class=\"number\">0</span>, <span class=\"number\">0.2</span>, (T,))</span><br><span class=\"line\"><span class=\"comment\">#生成正弦波并且添加高斯噪声</span></span><br><span class=\"line\">d2l.plot(time, [x], <span class=\"string\">&#x27;time&#x27;</span>, <span class=\"string\">&#x27;x&#x27;</span>, xlim=[<span class=\"number\">1</span>, <span class=\"number\">1000</span>], figsize=(<span class=\"number\">6</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\"><span class=\"comment\">#x轴数据、y轴数据、x轴标签、y轴标签、x轴显示范围、图表尺寸</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/12eda/Pictures@main/image-20251013170954572.png\" alt=\"image-20251013170954572\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">epoch：训练的完整周期</span><br><span class=\"line\">batch/mini-batch：分批训练</span><br><span class=\"line\">Iterations（迭代次数）也就是batch的数量</span><br><span class=\"line\">batchSize：每个batch包含的样本数量</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tau = <span class=\"number\">4</span></span><br><span class=\"line\">features = d2l.zeros((T - tau, tau))</span><br><span class=\"line\"><span class=\"comment\">#特征为996行，4列</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(tau):</span><br><span class=\"line\">    features[:, i] = x[i: T - tau + i]</span><br><span class=\"line\"><span class=\"comment\">#初始化特征矩阵</span></span><br><span class=\"line\">labels = d2l.reshape(x[tau:], (-<span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"><span class=\"comment\">#重塑一下标签矩阵</span></span><br><span class=\"line\"><span class=\"comment\">#@tab all</span></span><br><span class=\"line\">batch_size, n_train = <span class=\"number\">16</span>, <span class=\"number\">600</span></span><br><span class=\"line\"><span class=\"comment\"># 只有前n_train个样本用于训练</span></span><br><span class=\"line\">train_iter = d2l.load_array((features[:n_train], labels[:n_train]),</span><br><span class=\"line\">                            batch_size, is_train=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\">#创建好数据加载器，用于模型训练，用前600个样本，每次训练使用16个样本</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 初始化网络权重的函数</span></span><br><span class=\"line\"><span class=\"comment\">#如果是线性层，就要用Xavier方法初始化权重，自动计算合适的初始化范围</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">init_weights</span>(<span class=\"params\">m</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">type</span>(m) == nn.Linear:</span><br><span class=\"line\">        nn.init.xavier_uniform_(m.weight)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 一个简单的多层感知机</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_net</span>():</span><br><span class=\"line\">    net = nn.Sequential(nn.Linear(<span class=\"number\">4</span>, <span class=\"number\">10</span>),<span class=\"comment\">#输入4个特征，输出10个神经元</span></span><br><span class=\"line\">                        nn.ReLU(),<span class=\"comment\">#激活函数，非线性</span></span><br><span class=\"line\">                        nn.Linear(<span class=\"number\">10</span>, <span class=\"number\">1</span>))<span class=\"comment\">#通过10个神经元，输出一个预测值</span></span><br><span class=\"line\">    net.apply(init_weights)<span class=\"comment\">#给所有层应用权重初始化</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> net</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 平方损失。注意：MSELoss计算平方误差时不带系数1/2</span></span><br><span class=\"line\">loss = nn.MSELoss(reduction=<span class=\"string\">&#x27;none&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">net, train_iter, loss, epochs, lr</span>):</span><br><span class=\"line\">    trainer = torch.optim.Adam(net.parameters(), lr)</span><br><span class=\"line\">    <span class=\"comment\">#这是一个高度封装的的训练器，只需要传进去网络参数以及学习率就可以</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(epochs):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> train_iter:</span><br><span class=\"line\">            <span class=\"comment\">#训练的套路基本都是固定的</span></span><br><span class=\"line\">            trainer.zero_grad()</span><br><span class=\"line\">            l = loss(net(X), y)</span><br><span class=\"line\">            l.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\">            trainer.step()</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;epoch <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>&#125;</span>, &#x27;</span></span><br><span class=\"line\">              <span class=\"string\">f&#x27;loss: <span class=\"subst\">&#123;d2l.evaluate_loss(net, train_iter, loss):f&#125;</span>&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">net = get_net()</span><br><span class=\"line\">train(net, train_iter, loss, <span class=\"number\">5</span>, <span class=\"number\">0.01</span>)</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/12eda/Pictures@main/image-20251020153506378.png\" alt=\"image-20251020153506378\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">onestep_preds = net(features)</span><br><span class=\"line\"><span class=\"comment\">#调用的是net.__call__(features)</span></span><br><span class=\"line\"><span class=\"comment\">#得到996个预测值</span></span><br><span class=\"line\">d2l.plot([time, time[tau:]],</span><br><span class=\"line\">         [d2l.numpy(x), d2l.numpy(onestep_preds)], <span class=\"string\">&#x27;time&#x27;</span>,</span><br><span class=\"line\">         <span class=\"string\">&#x27;x&#x27;</span>, legend=[<span class=\"string\">&#x27;data&#x27;</span>, <span class=\"string\">&#x27;1-step preds&#x27;</span>], xlim=[<span class=\"number\">1</span>, <span class=\"number\">1000</span>],</span><br><span class=\"line\">         figsize=(<span class=\"number\">6</span>, <span class=\"number\">3</span>))</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/12eda/Pictures@main/image-20251013171030245.png\" alt=\"image-20251013171030245\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">multistep_preds = d2l.zeros(T)</span><br><span class=\"line\">multistep_preds[: n_train + tau] = x[: n_train + tau]</span><br><span class=\"line\"><span class=\"comment\">#前面的604个值都用真实数据填充</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n_train + tau, T):</span><br><span class=\"line\">    multistep_preds[i] = net(</span><br><span class=\"line\">        d2l.reshape(multistep_preds[i - tau: i], (<span class=\"number\">1</span>, -<span class=\"number\">1</span>)))</span><br><span class=\"line\">    <span class=\"comment\">#从第605开始，到1000，就开始用前四个来计算当前的值</span></span><br><span class=\"line\">    <span class=\"comment\">#误差会累积，所以越来越偏离</span></span><br><span class=\"line\"><span class=\"comment\">#@tab all</span></span><br><span class=\"line\">d2l.plot([time, time[tau:], time[n_train + tau:]],</span><br><span class=\"line\">         <span class=\"comment\">#原始数据、从第五个点开始：单步预测、从第605个点开始：多步预测</span></span><br><span class=\"line\">         [d2l.numpy(x), d2l.numpy(onestep_preds),</span><br><span class=\"line\">          d2l.numpy(multistep_preds[n_train + tau:])], <span class=\"string\">&#x27;time&#x27;</span>,</span><br><span class=\"line\">         <span class=\"string\">&#x27;x&#x27;</span>, legend=[<span class=\"string\">&#x27;data&#x27;</span>, <span class=\"string\">&#x27;1-step preds&#x27;</span>, <span class=\"string\">&#x27;multistep preds&#x27;</span>],</span><br><span class=\"line\">         xlim=[<span class=\"number\">1</span>, <span class=\"number\">1000</span>], figsize=(<span class=\"number\">6</span>, <span class=\"number\">3</span>))</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/12eda/Pictures@main/image-20251013163750873.png\" alt=\"image-20251013163750873\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#@tab all</span></span><br><span class=\"line\">max_steps = <span class=\"number\">64</span></span><br><span class=\"line\"><span class=\"comment\">#@tab mxnet, pytorch</span></span><br><span class=\"line\">features = d2l.zeros((T - tau - max_steps + <span class=\"number\">1</span>, tau + max_steps))</span><br><span class=\"line\"><span class=\"comment\"># 列i（i&lt;tau）是来自x的观测，其时间步从（i）到（i+T-tau-max_steps+1）</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(tau):</span><br><span class=\"line\">    features[:, i] = x[i: i + T - tau - max_steps + <span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 列i（i&gt;=tau）是来自（i-tau+1）步的预测，其时间步从（i）到（i+T-tau-max_steps+1）</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(tau, tau + max_steps):</span><br><span class=\"line\">    features[:, i] = d2l.reshape(net(features[:, i - tau: i]), -<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\">#%%</span></span><br><span class=\"line\"><span class=\"comment\">#只选择了4个有代表性的步长</span></span><br><span class=\"line\">steps = (<span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">16</span>, <span class=\"number\">64</span>)</span><br><span class=\"line\">d2l.plot([time[tau + i - <span class=\"number\">1</span>: T - max_steps + i] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> steps],</span><br><span class=\"line\">         [d2l.numpy(features[:, tau + i - <span class=\"number\">1</span>]) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> steps], <span class=\"string\">&#x27;time&#x27;</span>, <span class=\"string\">&#x27;x&#x27;</span>,</span><br><span class=\"line\">         legend=[<span class=\"string\">f&#x27;<span class=\"subst\">&#123;i&#125;</span>-step preds&#x27;</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> steps], xlim=[<span class=\"number\">5</span>, <span class=\"number\">1000</span>],</span><br><span class=\"line\">         figsize=(<span class=\"number\">6</span>, <span class=\"number\">3</span>))</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.jsdelivr.net/gh/12eda/Pictures@main/image-20251013170826366.png\" alt=\"image-20251013170826366\"></p>\n","text":"序列数据12345678T = 1000 # 总共产生1000个点time = d2l.arange(1, T + 1, dtype=d2l.float32)#...","permalink":"/post/序列数据","photos":[],"count_time":{"symbolsCount":"3.5k","symbolsTime":"3 mins."},"categories":[{"name":"技术","slug":"技术","count":3,"path":"api/categories/技术.json"}],"tags":[{"name":"深度学习","slug":"深度学习","count":3,"path":"api/tags/深度学习.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE\"><span class=\"toc-text\">序列数据</span></a></li></ol>","author":{"name":"Qushubiao","slug":"blog-author","avatar":"https://s2.loli.net/2025/10/18/RHJMI8AE6TVS21l.jpg","link":"/","description":"做难事必有所得","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"Kaggle房价预测","uid":"99cc996dc0617c9203fb12b8cb30ba1d","slug":"Kaggle房价预测","date":"2025-10-13T16:00:00.000Z","updated":"2025-10-20T14:02:05.729Z","comments":true,"path":"api/articles/Kaggle房价预测.json","keywords":null,"cover":[],"text":"Kaggle房价预测12345678# 若无法获得测试数据，则可根据训练数据计算均值和标准差numeric_features = all_features.dt...","permalink":"/post/Kaggle房价预测","photos":[],"count_time":{"symbolsCount":"4k","symbolsTime":"4 mins."},"categories":[{"name":"技术","slug":"技术","count":3,"path":"api/categories/技术.json"}],"tags":[{"name":"深度学习","slug":"深度学习","count":3,"path":"api/tags/深度学习.json"}],"author":{"name":"Qushubiao","slug":"blog-author","avatar":"https://s2.loli.net/2025/10/18/RHJMI8AE6TVS21l.jpg","link":"/","description":"做难事必有所得","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"深度学习笔记","uid":"dd8e371b161018fe37f17369405b9122","slug":"深度学习笔记","date":"2025-09-27T16:00:00.000Z","updated":"2025-10-20T14:02:29.999Z","comments":true,"path":"api/articles/深度学习笔记.json","keywords":null,"cover":null,"text":"深度学习 梯度下降算法：用来优化参数，让模型的预测更准确 1.1 计算梯度 1.2 更新参数（需要设置好学习率，就是步长） 1.3 不断重复，直到梯度为零 新的...","permalink":"/post/深度学习笔记","photos":[],"count_time":{"symbolsCount":277,"symbolsTime":"1 mins."},"categories":[{"name":"技术","slug":"技术","count":3,"path":"api/categories/技术.json"}],"tags":[{"name":"深度学习","slug":"深度学习","count":3,"path":"api/tags/深度学习.json"}],"author":{"name":"Qushubiao","slug":"blog-author","avatar":"https://s2.loli.net/2025/10/18/RHJMI8AE6TVS21l.jpg","link":"/","description":"做难事必有所得","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}